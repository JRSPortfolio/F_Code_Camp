{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-14 10:31:01.482935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1734172261.498236   10083 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1734172261.502995   10083 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-14 10:31:01.519070: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding, Bidirectional, Dense, Dropout #type: ignore\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "headers = ['type', 'message']\n",
        "train_ds = pd.read_csv(train_file_path, sep = '\\t', names = headers)\n",
        "test_ds = pd.read_csv(test_file_path, sep = '\\t', names = headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1734172263.532772   10083 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8218 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:2d:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "words = ' '.join(train_ds['message']).split()\n",
        "unique_words = len(set(words))\n",
        "message_lenghts = train_ds['message'].apply(lambda x: len(x.split()))\n",
        "max_length = int(message_lenghts.max())\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens = unique_words, output_mode = 'int', output_sequence_length = max_length)\n",
        "vectorizer.adapt(train_ds['message'])\n",
        "\n",
        "X_train = vectorizer(train_ds['message'])\n",
        "X_test = vectorizer(test_ds['message'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "\n",
        "y_train = encoder.fit_transform(train_ds['type'])\n",
        "y_test = encoder.transform(test_ds['type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8875 - auc: 0.7750 - loss: 0.3245 - precision: 0.5792 - val_accuracy: 0.9468 - val_auc: 0.9733 - val_loss: 0.2360 - val_precision: 0.7325\n",
            "Epoch 2/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9697 - auc: 0.9774 - loss: 0.1070 - precision: 0.9068 - val_accuracy: 0.9648 - val_auc: 0.9779 - val_loss: 0.1054 - val_precision: 0.9259\n",
            "Epoch 3/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9772 - auc: 0.9795 - loss: 0.0801 - precision: 0.9272 - val_accuracy: 0.9698 - val_auc: 0.9786 - val_loss: 0.1031 - val_precision: 0.8877\n",
            "Epoch 4/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9826 - auc: 0.9857 - loss: 0.0702 - precision: 0.9608 - val_accuracy: 0.9727 - val_auc: 0.9881 - val_loss: 0.0868 - val_precision: 0.8942\n",
            "Epoch 5/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9803 - auc: 0.9855 - loss: 0.0676 - precision: 0.9532 - val_accuracy: 0.9720 - val_auc: 0.9854 - val_loss: 0.0829 - val_precision: 0.9111\n",
            "Epoch 6/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9837 - auc: 0.9913 - loss: 0.0507 - precision: 0.9623 - val_accuracy: 0.9727 - val_auc: 0.9884 - val_loss: 0.0962 - val_precision: 0.8860\n",
            "Epoch 7/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9832 - auc: 0.9871 - loss: 0.0612 - precision: 0.9593 - val_accuracy: 0.9662 - val_auc: 0.9850 - val_loss: 0.0954 - val_precision: 0.8535\n",
            "Epoch 8/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9886 - auc: 0.9937 - loss: 0.0402 - precision: 0.9687 - val_accuracy: 0.9634 - val_auc: 0.9876 - val_loss: 0.1157 - val_precision: 0.8178\n",
            "Epoch 9/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9883 - auc: 0.9897 - loss: 0.0418 - precision: 0.9656 - val_accuracy: 0.9677 - val_auc: 0.9887 - val_loss: 0.1101 - val_precision: 0.8817\n",
            "Epoch 10/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9869 - auc: 0.9944 - loss: 0.0432 - precision: 0.9752 - val_accuracy: 0.9713 - val_auc: 0.9853 - val_loss: 0.1041 - val_precision: 0.8808\n",
            "Epoch 11/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9916 - auc: 0.9950 - loss: 0.0331 - precision: 0.9879 - val_accuracy: 0.9734 - val_auc: 0.9827 - val_loss: 0.1153 - val_precision: 0.9032\n",
            "Epoch 12/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9918 - auc: 0.9944 - loss: 0.0300 - precision: 0.9904 - val_accuracy: 0.9684 - val_auc: 0.9767 - val_loss: 0.1144 - val_precision: 0.8629\n",
            "Epoch 13/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9911 - auc: 0.9963 - loss: 0.0296 - precision: 0.9679 - val_accuracy: 0.9770 - val_auc: 0.9813 - val_loss: 0.0954 - val_precision: 0.9532\n",
            "Epoch 14/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9881 - auc: 0.9937 - loss: 0.0432 - precision: 0.9822 - val_accuracy: 0.9662 - val_auc: 0.9865 - val_loss: 0.1284 - val_precision: 0.8398\n",
            "Epoch 15/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9924 - auc: 0.9971 - loss: 0.0256 - precision: 0.9853 - val_accuracy: 0.9670 - val_auc: 0.9821 - val_loss: 0.1197 - val_precision: 0.8615\n",
            "Epoch 16/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9910 - auc: 0.9985 - loss: 0.0246 - precision: 0.9877 - val_accuracy: 0.9727 - val_auc: 0.9807 - val_loss: 0.1005 - val_precision: 0.8984\n",
            "Epoch 17/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9929 - auc: 0.9962 - loss: 0.0229 - precision: 0.9877 - val_accuracy: 0.9741 - val_auc: 0.9778 - val_loss: 0.1715 - val_precision: 0.8872\n",
            "Epoch 18/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9959 - auc: 0.9980 - loss: 0.0162 - precision: 0.9942 - val_accuracy: 0.9684 - val_auc: 0.9798 - val_loss: 0.1320 - val_precision: 0.8454\n",
            "Epoch 19/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9929 - auc: 0.9946 - loss: 0.0313 - precision: 0.9879 - val_accuracy: 0.9713 - val_auc: 0.9786 - val_loss: 0.1306 - val_precision: 0.8769\n",
            "Epoch 20/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9943 - auc: 0.9991 - loss: 0.0177 - precision: 0.9835 - val_accuracy: 0.9698 - val_auc: 0.9758 - val_loss: 0.1260 - val_precision: 0.8796\n",
            "Epoch 21/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9942 - auc: 0.9963 - loss: 0.0206 - precision: 0.9849 - val_accuracy: 0.9705 - val_auc: 0.9735 - val_loss: 0.1492 - val_precision: 0.8802\n",
            "Epoch 22/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9967 - auc: 0.9987 - loss: 0.0125 - precision: 0.9967 - val_accuracy: 0.9727 - val_auc: 0.9664 - val_loss: 0.1808 - val_precision: 0.9071\n",
            "Epoch 23/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9963 - auc: 0.9977 - loss: 0.0119 - precision: 0.9952 - val_accuracy: 0.9670 - val_auc: 0.9661 - val_loss: 0.2047 - val_precision: 0.8730\n",
            "Epoch 24/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9926 - auc: 0.9944 - loss: 0.0234 - precision: 0.9820 - val_accuracy: 0.9691 - val_auc: 0.9618 - val_loss: 0.1914 - val_precision: 0.8830\n",
            "Epoch 25/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9959 - auc: 0.9962 - loss: 0.0158 - precision: 0.9925 - val_accuracy: 0.9691 - val_auc: 0.9634 - val_loss: 0.1871 - val_precision: 0.8789\n",
            "Epoch 26/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9935 - auc: 0.9962 - loss: 0.0264 - precision: 0.9848 - val_accuracy: 0.9677 - val_auc: 0.9259 - val_loss: 0.2092 - val_precision: 0.9551\n",
            "Epoch 27/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9892 - auc: 0.9896 - loss: 0.0531 - precision: 0.9731 - val_accuracy: 0.9691 - val_auc: 0.9720 - val_loss: 0.1385 - val_precision: 0.8636\n",
            "Epoch 28/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9981 - auc: 0.9989 - loss: 0.0099 - precision: 0.9936 - val_accuracy: 0.9691 - val_auc: 0.9748 - val_loss: 0.1474 - val_precision: 0.8711\n",
            "Epoch 29/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9972 - auc: 0.9958 - loss: 0.0122 - precision: 0.9979 - val_accuracy: 0.9727 - val_auc: 0.9648 - val_loss: 0.1917 - val_precision: 0.8901\n",
            "Epoch 30/30\n",
            "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9976 - auc: 0.9972 - loss: 0.0097 - precision: 0.9993 - val_accuracy: 0.9684 - val_auc: 0.9731 - val_loss: 0.1761 - val_precision: 0.8522\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fdbd015ffe0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.Sequential([Embedding(max_length, 64),\n",
        "                             Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "                             Dense(128, activation = 'relu'),\n",
        "                             Dense(16, activation = 'relu'),\n",
        "                             Dropout(0.3),\n",
        "                             Dense(1, activation = 'sigmoid')])\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy', 'precision', 'auc'])\n",
        "model.fit(X_train, y_train, epochs = 30, validation_data=(X_test, y_test), batch_size = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "message = vectorizer([\"how are you doing today?\"])\n",
        "pred = model.predict(message)\n",
        "\n",
        "print(pred[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
            "['', 'ham']\n"
          ]
        }
      ],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  vectorized_text = vectorizer([pred_text])\n",
        "  pred = model.predict(vectorized_text)\n",
        "  if pred[0][0] > 0.5:\n",
        "    prediction = 'spam'\n",
        "  else:\n",
        "    prediction = 'ham'\n",
        "\n",
        "  return (['', prediction])\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "pred: ham --- ans: ham\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "pred: spam --- ans: spam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "pred: ham --- ans: ham\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "pred: spam --- ans: spam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "pred: spam --- ans: spam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "pred: ham --- ans: ham\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "pred: ham --- ans: ham\n",
            "You passed the challenge. Great job!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    print(f'pred: {prediction[1]} --- ans: {ans}')\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "myvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
